{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a445e139-a70f-42a7-b622-ce7b59ecce1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @author izhangxm\n",
    "# Copyright 2017 izhangxm@gmail.com. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fda08e-37e5-470c-aca7-49be59cc4cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "from itertools import product\n",
    "import os.path as osp\n",
    "from scipy.optimize import leastsq\n",
    "import time\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.integrate import odeint\n",
    "import math\n",
    "# from tqdm import tqdm, trange\n",
    "from tqdm.notebook import  tqdm\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "az.style.use(\"arviz-darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c5995b-88f0-4e33-abd7-f5c5873d83d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core_lib import MyDataset, r2_loss, get_target, plot_dataset\n",
    "from core_lib import get_dcdts_for_scipy_odeint, get_dcdts_for_solve_ivp\n",
    "from core_lib import MY_EPSILON\n",
    "from core_lib import set_pbar_start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1397666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "db_csv_path = \"dataset/data.csv\"\n",
    "dataset = MyDataset(db_csv_path)\n",
    "df = dataset.get_df()\n",
    "cct_names, rates_names, error_names = dataset.get_var_col_names()\n",
    "c0 = df[cct_names].iloc[0].values\n",
    "t_eval = dataset.get_df()['time'].values\n",
    "\n",
    "# # 假设都是一级动力学\n",
    "# k_kinetics = np.repeat(1, 11).astype(np.uint8)\n",
    "# ## k_kinetics = np.array([0,0,0,0,1,1,0,0,1,1,0]).astype(np.uint8)\n",
    "# ks = np.array([0.00071942, 0.00269696, 0.00498945, 0.00444931, 0.00571299, 0.00801272, 0.00131931, 0.00319959, 0.00415571, 0.00228432, 0.00177611])\n",
    "# dataset.set_as_sim_dataset(t_eval, c0, t0=0.5, args=(ks, k_kinetics))\n",
    "# df = dataset.get_df()\n",
    "\n",
    "# plot_dataset(dataset, dataset)\n",
    "dataset.get_real_cct_names()\n",
    "dataset.get_real_ccts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f0625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.get_var_col_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c81a624-0229-427d-a14b-60724b2498a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ltq_fit_rk(dataset, t_eval, c0,   k_kinetics, maxfev=2400, plot_trace=False, show_process=True, pbar=None, pbar_prefix=\"\"):\n",
    "\n",
    "    ee = np.array(MY_EPSILON)\n",
    "    \n",
    "    def _error_loss(ks, *args):\n",
    "        dataset, c0, t_eval, pbar,loss_trace,r2_trace, ks_trace, pbar_prefix = args\n",
    "        #------------------------\n",
    "        cct_names = dataset.get_real_cct_names()\n",
    "        real_index = dataset.get_real_cct_names_indexs()\n",
    "        \n",
    "        df = dataset.get_df()\n",
    "        timelist = df['time'].values\n",
    "        ccts = dataset.get_real_ccts()\n",
    "        #------------------------\n",
    "\n",
    "        sol_res = solve_ivp(get_dcdts_for_solve_ivp(), (t_eval.min(), t_eval.max()), c0, t_eval=t_eval, method='Radau', args=(ks, k_kinetics))\n",
    "        # sol_res = solve_ivp(get_dcdts_for_solve_ivp(), (t_eval.min(), t_eval.max()), c0, t_eval=t_eval, method='BDF', args=(ks, k_kinetics))\n",
    "        # sol_res = solve_ivp(get_dcdts_for_solve_ivp(), (t_eval.min(), t_eval.max()), c0, t_eval=t_eval, method='DOP853', args=(ks, k_kinetics))\n",
    "        cs = sol_res.y\n",
    "        t_eval = sol_res.t\n",
    "\n",
    "        # res = odeint(func=get_dcdts_for_scipy_odeint(), y0=c0, t=t_eval, args=(ks,k_kinetics))\n",
    "        # cs = np.transpose(res, [1,0])\n",
    "\n",
    "        ccts_predict = []\n",
    "        for _t, cctsob_at_t in zip(timelist, ccts):\n",
    "            _i = np.argwhere(t_eval == _t)\n",
    "            if len(_i) > 0:\n",
    "                _i = int(_i[0])\n",
    "                cct_at_t = cs[:, _i]\n",
    "                cct_at_t = cct_at_t[real_index]\n",
    "            else:\n",
    "                cct_at_t = -cctsob_at_t * 1000\n",
    "\n",
    "            ccts_predict.append(cct_at_t)\n",
    "\n",
    "        ccts_predict = np.array(ccts_predict)\n",
    "\n",
    "        loss = (np.abs(ccts - ccts_predict) * ee ).reshape(-1)\n",
    "        r2_all = r2_loss(ccts, ccts_predict)\n",
    "        loss_sum = loss.sum()\n",
    "\n",
    "        _var_r2s = []\n",
    "        for _cct_pre, _cct_y in zip(np.transpose(ccts_predict, [1, 0]), np.transpose(ccts, [1, 0]), ):\n",
    "            _r2 = r2_loss(_cct_pre, _cct_y)\n",
    "            _var_r2s.append(_r2)\n",
    "        _var_r2s = np.array(_var_r2s)\n",
    "\n",
    "        _var_r2s_s = [f\"{_c}:{x:.04f}\" for x, _c in zip(_var_r2s, cct_names)]\n",
    "        _r2s_str = \",\".join(_var_r2s_s)\n",
    "\n",
    "\n",
    "        r2_dict = {\"r2_all\":r2_all, \"r2_detail\":_var_r2s}\n",
    "\n",
    "        if pbar:\n",
    "            # p_str = f\"r2_all:{r2_all:.04f} {_r2s_str}, loss_sum:{loss_sum:.04f}\"\n",
    "            p_str = f\"r2_all:{r2_all:.04f} , loss_sum:{loss_sum:.04f} r2_mean:{_var_r2s.mean():.04f}\"\n",
    "            pbar.set_description(f\"{pbar_prefix}{p_str}\")\n",
    "            pbar.update(1)\n",
    "            pbar.refresh()\n",
    "\n",
    "        loss_trace.append(loss_sum)\n",
    "        r2_trace.append(r2_dict)\n",
    "        ks_trace.append(ks)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    loss_trace = []\n",
    "    r2_trace = []\n",
    "    ks_trace = []\n",
    "\n",
    "\n",
    "    if show_process:\n",
    "        if pbar is None:\n",
    "            pbar =tqdm(total=maxfev, ascii=True)\n",
    "        else:\n",
    "            pbar.reset(total=maxfev)\n",
    "            set_pbar_start(pbar=pbar, n=0)\n",
    "    else:\n",
    "        pbar = None\n",
    "\n",
    "    ks_o = np.repeat(0.0001, 11).tolist()\n",
    "    ks_res = leastsq(_error_loss, ks_o, maxfev=maxfev, args=(dataset, c0, t_eval, pbar,loss_trace,r2_trace, ks_trace, pbar_prefix),ftol=1.49012e-8, xtol=1.49012e-8)[0]\n",
    "\n",
    "    if plot_trace:\n",
    "        X = range(len(loss_trace))\n",
    "\n",
    "        fig, axes = plt.subplots(1, 3, sharex=True, figsize=(15, 5))\n",
    "        axes[0].plot(X, loss_trace, alpha=0.6)\n",
    "        axes[1].plot(X, r2_trace['r2_all'], alpha=0.6)\n",
    "        axes[0].set_xlabel(\"iters\")\n",
    "        axes[0].set_ylabel(\"loss_sum\")\n",
    "        axes[1].set_xlabel(\"iters\")\n",
    "        axes[1].set_ylabel(\"r2\")\n",
    "\n",
    "        ks_trace = np.transpose(np.array(ks_trace), [1, 0])\n",
    "        for _ks in ks_trace:\n",
    "            axes[2].plot(X, _ks, alpha=0.6)\n",
    "\n",
    "    return ks_res, r2_trace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e40b21f-fd01-4eb9-a98b-3617e745b4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_kinetics = np.repeat(1, 11).astype(np.uint8)\n",
    "\n",
    "t_eval = dataset.get_df()['time'].values\n",
    "c0 = df[cct_names].iloc[0].values\n",
    "ks_res, r2_trace = ltq_fit_rk(dataset,t_eval, c0, k_kinetics, maxfev=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1836e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "def research_kk_list(kk_list_all, res_dict_save_path, bad_keys=[]):\n",
    "    # 保存计算的结果，并载入已经计算的结果\n",
    "    res_dict = {}\n",
    "    \n",
    "    \n",
    "    if os.path.exists(res_dict_save_path):\n",
    "        res_dict = torch.load(res_dict_save_path)\n",
    "    # 保存的间隔\n",
    "    save_iter = 2\n",
    "    n = len(res_dict.keys())\n",
    "\n",
    "    # 需要遍历的模型组合\n",
    "    # kk_list_all = [list(x) for x in product([0,1], repeat=11)]\n",
    "    # 反向计算序列，从最大的可能性开始计算\n",
    "    # kk_list_all = kk_list_all[::-1]\n",
    "    \n",
    "    # 总进度条和子进度条\n",
    "    pbar =tqdm(total=len(kk_list_all), ascii=True)\n",
    "    sub_bar = tqdm(total=len(kk_list_all), ascii=True)\n",
    "\n",
    "    # 总进度条恢复进度\n",
    "    pbar = set_pbar_start(pbar, n)\n",
    "\n",
    "    \n",
    "\n",
    "    # 循环计算\n",
    "    for ii, k_kinetics in enumerate(kk_list_all):\n",
    "        key = \"\".join([f\"{_}\" for _ in k_kinetics])\n",
    "        if key in res_dict or key in bad_keys:\n",
    "            continue\n",
    "        \n",
    "        pbar.set_description(f\"total progress: {key}\")\n",
    "        pbar.update(1)\n",
    "        pbar.refresh()\n",
    "        \n",
    "        ks_res, r2_trace = ltq_fit_rk(dataset,t_eval, c0, k_kinetics, maxfev=3000, plot_trace=False, show_process=True, pbar=sub_bar)\n",
    "        # _dd = r2_trace[-1]['r2_detail']\n",
    "        # r2_mean = _dd.mean()\n",
    "        # r2_all = r2_trace[-1]['r2_all']\n",
    "        # _t = k_kinetics + list(_dd) + [r2_mean, r2_all]\n",
    "        \n",
    "        res_dict[key] = {\"ks_res\":ks_res, \"r2_trace_lastest\":r2_trace[-1]}\n",
    "        \n",
    "        if ii % save_iter == 0:\n",
    "            torch.save(res_dict, res_dict_save_path)\n",
    "\n",
    "    # r2_all = np.array(r2_all_list)\n",
    "    # dfr2 = pd.DataFrame(r2_all, columns=[ f\"k{x+1}\" for x  in range(11) ] + [f'r2_{c}' for c in cct_names] + [\"r2_mean\", \"r2_all\"])\n",
    "    # dfr2.to_csv(\"runtime/r2_all_v2.csv\")\n",
    "\n",
    "    torch.save(res_dict, res_dict_save_path)\n",
    "    return res_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdce3d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kk_list_all = [\n",
    "    [0,1,1,1,1,1,1,1,1,0,1],\n",
    "    [0,1,1,1,1,1,1,1,1,1,1],\n",
    "    [1,1,1,1,1,1,1,1,1,0,1],\n",
    "    [1,1,1,1,1,1,1,1,1,1,1],\n",
    "    ]\n",
    "rr = research_kk_list(kk_list_all, \"runtime/lsq_res_dict_possible.pt\");\n",
    "for key, v in rr.items():\n",
    "    print(key, v)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8fff65",
   "metadata": {},
   "outputs": [],
   "source": [
    "kk_list_all = [list(x) for x in product([0,1], repeat=11)]\n",
    "kk_list_all = kk_list_all[::-1]\n",
    "bad_keys = [\"11011010101\", \"10010100001\", \"01111011010\",\"01111010110\", \"01111010101\",\"01111001101\"]\n",
    "\n",
    "research_kk_list(kk_list_all, \"runtime/lsq_res_dict.pt\", bad_keys=bad_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208c571b-3326-4315-946a-60be67f1779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ks_res, r2_trace = ltq_fit_rk(dataset, t_eval, c0, k_kinetics, maxfev=5000, plot_trace=False, show_process=True, pbar=None)\n",
    "\n",
    "dcdt_func = get_dcdts_for_solve_ivp()\n",
    "\n",
    "\n",
    "ks = ks_res\n",
    "res = solve_ivp(get_dcdts_for_solve_ivp(), (t_eval.min(), t_eval.max()), c0, method='Radau', t_eval=t_eval, args=(ks, k_kinetics))\n",
    "cs = res.y\n",
    "t_eval = res.t\n",
    "\n",
    "\n",
    "# res = odeint(func=get_dcdts_for_scipy_odeint(), y0=c0, t=t_eval, args=(ks,k_kinetics))\n",
    "# cs = np.transpose(res, [1,0])\n",
    "\n",
    "# 计算导数曲线\n",
    "derivative = []\n",
    "# 10*150\n",
    "dcdt_df = pd.DataFrame(columns=['time'] + cct_names)\n",
    "\n",
    "\n",
    "for i, t in enumerate(t_eval):\n",
    "    cct = cs[:, i]\n",
    "    dcdts = dcdt_func(t, cct, ks, k_kinetics)\n",
    "    dcdt_df.loc[len(dcdt_df.index)] = [t] + list(dcdts)\n",
    "\n",
    "cols = 5\n",
    "rows = math.ceil(len(cct_names) / cols)\n",
    "\n",
    "fig, fig_axes = plt.subplots(ncols=cols, nrows=rows, figsize=(4.2 * cols, 4 * rows), dpi=100)\n",
    "if isinstance(fig_axes, np.ndarray):\n",
    "    fig_axes = fig_axes.reshape(-1)\n",
    "else:\n",
    "    fig_axes = [fig_axes]\n",
    "\n",
    "for i, axes in enumerate(fig_axes):\n",
    "    if i >= len(cct_names):\n",
    "        axes.axis('off')\n",
    "        continue\n",
    "\n",
    "    y_name = cct_names[i]\n",
    "    Y = df[y_name].values\n",
    "    axes.plot(df['time'].values, Y, '*', label=f\"ob\")\n",
    "    axes.set_ylabel(f'cct_{y_name}')\n",
    "    axes.set_xlabel(f'time(h)')\n",
    "\n",
    "    # axes.plot(df['time'].values, df[rates_names[i]].values, '+', label=f\"rate\")\n",
    "\n",
    "    axes.plot(t_eval, cs[i, :], 'r', label=f\"c(t)\")\n",
    "    # axes.plot(t_eval, dcdt_df[y_name].values,'g', label=f\"c'(t)\")\n",
    "\n",
    "    axes.legend()\n",
    "    # axes.set_title(f\"{y_name}\", fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f72c53-decf-45f4-91fd-9c2129f1435a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
